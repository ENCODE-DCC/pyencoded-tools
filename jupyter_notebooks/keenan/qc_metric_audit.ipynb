{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 50\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up authentication for requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copied from pyencoded-tools/encodedcc.py to avoid dependency.\n",
    "class ENC_Key:\n",
    "    def __init__(self, keyfile, keyname):\n",
    "        if os.path.isfile(str(keyfile)):\n",
    "            keys_f = open(keyfile, 'r')\n",
    "            keys_json_string = keys_f.read()\n",
    "            keys_f.close()\n",
    "            keys = json.loads(keys_json_string)\n",
    "        else:\n",
    "            keys = keyfile\n",
    "        key_dict = keys[keyname]\n",
    "        self.authid = key_dict['key']\n",
    "        self.authpw = key_dict['secret']\n",
    "        self.server = key_dict['server']\n",
    "        if not self.server.endswith(\"/\"):\n",
    "            self.server += \"/\"\n",
    "\n",
    "            \n",
    "class ENC_Connection(object):\n",
    "    def __init__(self, key):\n",
    "        self.headers = {'content-type': 'application/json', 'accept': 'application/json'}\n",
    "        self.server = key.server\n",
    "        self.auth = (key.authid, key.authpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class to extract data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtractedQCData(object):\n",
    "    \"\"\"Class to store extracted QC data\n",
    "    from ENCODE search results.\"\"\"\n",
    "    def __init__(self, file):\n",
    "        self.accession = file['accession']\n",
    "        self.file_status = file['status']\n",
    "        self.file_format = file['file_format']\n",
    "        self.assembly = file['assembly']\n",
    "        self.dataset = file['dataset']\n",
    "        self.date_file_created = file['date_created']\n",
    "        self.output_type = file['output_type']\n",
    "        try:\n",
    "            self.analysis_name = file['analysis_step_version']['analysis_step']['name']\n",
    "        except KeyError:\n",
    "            self.analysis_name = np.nan\n",
    "        self.quality_metrics = []\n",
    "        for metric in file['quality_metrics']:\n",
    "            try:\n",
    "                assay_term_name = metric['assay_term_name']\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    assay_term_name = file['analysis_step_version']['analysis_step']\\\n",
    "                                                   ['pipelines'][0]['assay_term_name']\n",
    "                except (KeyError, IndexError):\n",
    "                    assay_term_name = np.nan\n",
    "            try:\n",
    "                # Only for SamtoolFlagstatsQualityMetrics\n",
    "                processing_stage = metric['processing_stage']\n",
    "            except KeyError:\n",
    "                processing_stage = 'unknown'\n",
    "            metric_data = {\n",
    "                'uuid': metric['uuid'],\n",
    "                '@type': metric['@type'][0],\n",
    "                'qc_status': metric['status'],\n",
    "                'quality_metric_of': [x for x in metric['quality_metric_of']],\n",
    "                'date_qc_created': metric['date_created'],\n",
    "                'assay_term_name': assay_term_name,\n",
    "                'processing_stage': processing_stage\n",
    "                }\n",
    "            self.quality_metrics.append(metric_data)\n",
    "        self.metric_count = len(self.quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull all Files with quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(url, output_json='qc_metrics.json', auth=False, force_update=False):\n",
    "    \"\"\"Gets data from ENCODE and stores\n",
    "    it in output_file. If output_file already\n",
    "    exists then it will use cached version.\n",
    "    Set force_update=True to update cached file.\n",
    "    WARNING: Does not update data automatically\n",
    "    if search URL is changed. Use force_update=True.\n",
    "    Can pass auth=(key.authid, key.authpw)\n",
    "    to return non-public results. Returns pandas \n",
    "    DataFrame object.\"\"\"\n",
    "    if not output_json.endswith('.json'):\n",
    "        raise ValueError(\"Output file must be a .json\")\n",
    "    if os.path.isfile(output_json) and not force_update:\n",
    "            data = pd.read_json(output_json)\n",
    "    else:\n",
    "        r = requests.get(url, auth=auth)\n",
    "        search_results = r.json()['@graph']\n",
    "        results = []\n",
    "        for file in search_results:\n",
    "            extracted_data = ExtractedQCData(file)\n",
    "            results.append(extracted_data)\n",
    "        data = pd.DataFrame([vars(r) for r in results])\n",
    "        data.to_json(output_json)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tidy_data(data):\n",
    "    \"\"\"Extracts data from quality_metric\n",
    "    column, returning a tidy dataset where\n",
    "    each quality_metric has its own row. Since\n",
    "    several quality_metrics can refer to same file,\n",
    "    this will duplicate accession and other high-level\n",
    "    metadata.\"\"\"\n",
    "    # Convert DataFrame to list of objects. \n",
    "    results = data.to_dict(orient='records')\n",
    "    # Make tidy data from list of QC metrics. \n",
    "    data = pd.io.json.json_normalize([r for r in results],\n",
    "                                     'quality_metrics',\n",
    "                                     [x for x in results[0].keys() if x != 'quality_metrics'])\n",
    "    # Convert date information to datetime type.\n",
    "    data[['date_qc_created',\n",
    "          'date_file_created']] = data[['date_qc_created',\n",
    "                                        'date_file_created']].apply(pd.to_datetime)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define key if private data desired.\n",
    "key = ENC_Key(os.path.expanduser(\"~/keypairs.json\"), 'prod')\n",
    "# Define query to return objects.\n",
    "url = 'https://www.encodeproject.org/'\\\n",
    "            'search/?type=File&quality_metrics.uuid=%2A'\\\n",
    "            '&format=json&limit=all'\n",
    "        \n",
    "#frame=object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data(url, auth=(key.authid, key.authpw), force_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td = tidy_data(data)\n",
    "#td['date_qc_created'] = td['date_qc_created'].apply(lambda x: x.strftime('%m-%d-%Y'))\n",
    "#td['date_qc_created'] = td['date_qc_created'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td = td.fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "## Value counts for main columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.assay_term_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.analysis_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td['@type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.file_format.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.file_format.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.processing_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processing_stage_data = td[['accession', 'uuid', 'processing_stage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull all files that should have quality_metrics but don't (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_format_url = '&file_format='.join([x for x in expected_file_format])\n",
    "output_type_url = '&output_type='.join([x.replace(' ', '+') for x in expected_output_type])\n",
    "url = 'https://www.encodeproject.org/search/?type=File'\\\n",
    "      '&file_format={}&output_type={}&quality_metrics.uuid!=*'\\\n",
    "      '&format=json&limit=all'.format(file_format_url,\n",
    "                                      output_type_url)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(url, auth=(key.authid, key.authpw))\n",
    "search_results = r.json()['@graph']\n",
    "result_list = []\n",
    "for file in search_results:\n",
    "    try:\n",
    "        analysis_name = file['analysis_step_version']['analysis_step']['name']\n",
    "    except KeyError:\n",
    "        analysis_name = 'unknown'\n",
    "    try:\n",
    "        assay_term_name = file['analysis_step_version']['analysis_step']['pipelines'][0]['assay_term_name']\n",
    "    except (KeyError, IndexError):\n",
    "        assay_term_name = 'unknown'\n",
    "    try:\n",
    "        assembly = file['assembly']\n",
    "    except KeyError:\n",
    "        assembly = 'unknown'\n",
    "    extracted_results = {\n",
    "        'accession': file['accession'],\n",
    "        'assay_term_name': assay_term_name,\n",
    "        'lab': file['lab']['title'],\n",
    "        'file_format': file['file_format'],\n",
    "        'status': file['status'],\n",
    "        'assembly': assembly,\n",
    "        'dataset': file['dataset'],\n",
    "        'date_file_created': file['date_created'],\n",
    "        'output_type': file['output_type'],\n",
    "        'analysis_name': analysis_name\n",
    "    }\n",
    "    if extracted_results['analysis_name'] in expected_analysis_name:\n",
    "        result_list.append(extracted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_qc[no_qc.lab == 'ENCODE Processing Pipeline'].drop(['accession',\n",
    "                                                       'dataset',\n",
    "                                                       'date_file_created'],\n",
    "                                                        axis=1).apply(pd.Series.value_counts)\\\n",
    "                                                        .sort_values([x for x in ['analysis_name',\n",
    "                                                                                  'assembly',\n",
    "                                                                                  'lab',\n",
    "                                                                                  'output_type',\n",
    "                                                                                  'status']], ascending=False)\\\n",
    "                                                                                  .T.stack().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Files with expected file_format of:\n",
    "expected_file_format = ['bam',\n",
    "                        'bed',\n",
    "                        'bigBed',\n",
    "                        'tsv',\n",
    "                        'bigWig']\n",
    "\n",
    "# Files with expected output_type of:\n",
    "expected_output_type = ['unfiltered alignments', \n",
    "                        'conservative idr thresholded peaks',\n",
    "                        'hotspots',\n",
    "                        'optimal idr thresholded peaks',\n",
    "                        'alignments',\n",
    "                        'transcriptome alignments',\n",
    "                        'gene quantifications',\n",
    "                        'transcription start sites',\n",
    "                        'signal of unique reads',\n",
    "                        'peaks',\n",
    "                        'pseudoreplicated idr thresholded peaks',\n",
    "                        'methylation state at CHG',\n",
    "                        'methylation state at CHH',\n",
    "                        'signal',\n",
    "                        'methylation state at CpG',\n",
    "                        'filtered peaks']\n",
    "\n",
    "# Files with expected analysis_name of:\n",
    "expected_analysis_name = ['bwa-alignment-step-v-1',\n",
    "                          'tf-idr-step',\n",
    "                          'dnase-call-hotspots-v-1',\n",
    "                          'tf-idr-peaks-to-bigbed-step',\n",
    "                          'kundaje-lab-atac-seq-trim-align-filter-single-rep-v1',\n",
    "                          'kundaje-lab-atac-seq-idr-v1', 'dnase-align-bwa-se-v-1',\n",
    "                          'dnase-filter-se-v-1', 'lrna-pe-star-alignment-step-v-1',\n",
    "                          'lrna-pe-rsem-quantification-v-1', 'rampage-idr-step-v-1',\n",
    "                          'dnase-call-hotspots-alt-v-1', 'lrna-pe-tophat-alignment-step-v-1',\n",
    "                          'ggr_tr1_rna_seq_trimming_mapping_step',\n",
    "                          'rampage-grit-peak-calling-step-v-1',\n",
    "                          'kundaje-lab-atac-seq-trim-align-filter-v1',\n",
    "                          'modern-chip-seq-peaks-to-bigbed-step-v-1',\n",
    "                          'modern-bwa-alignment-step-v-1',\n",
    "                          'modern-chip-seq-optimal-idr-step-v-1',\n",
    "                          'lrna-se-star-alignment-step-v-1',\n",
    "                          'dme-align-pe-v-1',\n",
    "                          'rampage-pe-alignment-step-v-1',\n",
    "                          'bwa-raw-alignment-step-v-1',\n",
    "                          'lrna-se-rsem-quantification-step-v-1',\n",
    "                          'dnase-align-bwa-pe-v-1',\n",
    "                          'dnase-filter-pe-v-1',\n",
    "                          'small-rna-se-star-alignment-step-v-2',\n",
    "                          'tf-unreplicated-idr-step',\n",
    "                          'ggr_tr1_chip_seq_mapping_filtering_step',\n",
    "                          'dme-extract-se-v-2',\n",
    "                          'mott-trim-align-bismark-v-1-0',\n",
    "                          'kundaje-lab-atac-seq-unreplicated-idr-single-rep-v1',\n",
    "                          'dme-extract-pe-v-1',\n",
    "                          'tf-unreplicated-idr-peaks-to-bigbed-step',\n",
    "                          'uknown',\n",
    "                          'modern-chip-seq-filter-for-optimal-idr-peaks-step-v-1',\n",
    "                          'lrna-se-tophat-alignment-step-v-1',\n",
    "                          'modern-chip-seq-optimal-idr-thresholded-peaks-to-bigbed-step-v-1',\n",
    "                          'kundaje-lab-atac-seq-peak-call-single-rep-v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc_grouped = no_qc.groupby(['assay_term_name',\n",
    "                               'file_format',\n",
    "                               'analysis_name',\n",
    "                               'output_type',\n",
    "                               'accession']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_qc_unstacked = no_qc_grouped[['status']].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc_unstacked_transformed = no_qc_unstacked.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc_unstacked_summary = no_qc_unstacked_transformed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc_unstacked_summary_transformed = no_qc_unstacked_summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_qc_dict = no_qc_unstacked_summary_transformed[['mean']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in no_qc_dict['mean'].keys():\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in summary_expected_dict.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate expected number of quality_metrics for specified type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qc_metric_requirements = pd.read_csv(\"qc_metric_requirements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_data = td.groupby(['assay_term_name',\n",
    "                           'file_format',\n",
    "                           'analysis_name',\n",
    "                           'output_type',\n",
    "                           '@type',       \n",
    "                           'processing_stage',\n",
    "                           'accession']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuid_grouped_data = grouped_data[['uuid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unstacked_uuid_grouped_data = uuid_grouped_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unstacked_uuid_grouped_data_transformed = unstacked_uuid_grouped_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_unstacked_uuid_grouped_data_transformed = unstacked_uuid_grouped_data_transformed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_transformed = summary_unstacked_uuid_grouped_data_transformed.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_transformed['mean'] = summary_transformed['mean'].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_transformed_selected = summary_transformed[['count', 'min', 'mean', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_expected_dict = summary_transformed_selected[['mean']].to_dict()['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "required_number = []\n",
    "for i, y in summary_expected_dict.items():\n",
    "    qc_metric_details = {'assay_term_name': i[0],\n",
    "                          'file_format': i[1],\n",
    "                          'analysis_name': i[2],\n",
    "                          'output_type': i[3],\n",
    "                          '@type': i[4],\n",
    "                          'processing_stage': i[5],\n",
    "                          'count': y}\n",
    "    required_number.append(qc_metric_details)\n",
    "required_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qc_metric_requirements = pd.DataFrame(required_number)[['assay_term_name',\n",
    "                                                        'file_format',\n",
    "                                                        'analysis_name',\n",
    "                                                        'output_type',\n",
    "                                                        '@type',\n",
    "                                                        'processing_stage',\n",
    "                                                        'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qc_metric_requirements = pd.read_csv(\"qc_metric_requirements.csv\")\n",
    "#qc_metric_requirements.to_csv(\"qc_metric_requirements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qc_metric_requirements.groupby(['assay_term_name',\n",
    "                               'file_format',\n",
    "                               'analysis_name',\n",
    "                               'output_type',\n",
    "                               '@type',\n",
    "                               'processing_stage',\n",
    "                               'count']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in summary_expected_dict.keys():\n",
    "    if 'rampage-pe-alignment-step-v-1' in i:\n",
    "        print(i)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, y in summary_expected_dict.items():\n",
    "    if y > 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert summary_expected_dict[('CAGE',\n",
    "                              'bam',\n",
    "                              'rampage-pe-alignment-step-v-1',\n",
    "                              'alignments',\n",
    "                              'SamtoolsFlagstatsQualityMetric',\n",
    "                              'unknown')] == 1\n",
    "assert summary_expected_dict[('ChIP-seq',\n",
    "                              'bam',\n",
    "                              'bwa-alignment-step-v-1',\n",
    "                              'alignments',\n",
    "                              'SamtoolsFlagstatsQualityMetric',\n",
    "                              'filtered')] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#td['date_qc_created'] = td['date_qc_created'].apply(lambda x: x.strftime('%m-%d-%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find files that have unexpected number of quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only files that haven't been revoked/deleted etc.\n",
    "active_files = td[~(td.file_status.isin(['revoked',\n",
    "                                        'deleted',\n",
    "                                        'replaced',\n",
    "                                        'content error']))].groupby(['accession',\n",
    "                                                                    'assay_term_name',\n",
    "                                                                    'file_format',\n",
    "                                                                    'analysis_name',\n",
    "                                                                    'output_type',\n",
    "                                                                    '@type',\n",
    "                                                                    'assembly']).count()[['uuid']].reset_index()\n",
    "active_files = active_files.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All file statuses\n",
    "active_files = td.groupby(['accession',\n",
    "                        'assay_term_name',\n",
    "                        'file_format',\n",
    "                        'analysis_name',\n",
    "                        'output_type',\n",
    "                        '@type',\n",
    "                        'assembly',\n",
    "                        'processing_stage']).count()[['uuid']]#.reset_index()\n",
    "active_files = active_files.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_files['mapping_key'] = list(zip(active_files.assay_term_name,\n",
    "                                        active_files.file_format,\n",
    "                                        active_files.analysis_name,\n",
    "                                        active_files.output_type,\n",
    "                                        active_files['@type'],\n",
    "                                        active_files.processing_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_files['expected_number'] = active_files['mapping_key'].apply(lambda x: summary_expected_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_files[active_files.uuid != active_files.expected_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "active_files_mismatch = active_files[active_files.uuid != active_files.expected_number]\\\n",
    "                                                .rename(columns={'uuid': 'actual_number'})\\\n",
    "                                                [['accession',\n",
    "                                                  'assay_term_name',\n",
    "                                                  'analysis_name',\n",
    "                                                  'assembly',\n",
    "                                                  'output_type',\n",
    "                                                  '@type',\n",
    "                                                  'processing_stage',\n",
    "                                                  'expected_number',\n",
    "                                                  'actual_number']].sort_values(['assembly',\n",
    "                                                                                 'output_type',\n",
    "                                                                                 '@type',\n",
    "                                                                                 'actual_number'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afm = active_files_mismatch.merge(td, how='left', on=['accession',\n",
    "                                                '@type',\n",
    "                                                'assay_term_name',\n",
    "                                                'analysis_name',\n",
    "                                                'assembly',\n",
    "                                                'output_type',\n",
    "                                                'processing_stage'])\n",
    "afm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afm.groupby(['assay_term_name',\n",
    "              'accession',\n",
    "              'output_type',\n",
    "              '@type',\n",
    "              'processing_stage',\n",
    "              'expected_number',\n",
    "              'actual_number',\n",
    "              'qc_status',\n",
    "              'uuid',\n",
    "              'date_qc_created',\n",
    "              'assembly',\n",
    "              'analysis_name',\n",
    "              'file_format',\n",
    "              'date_file_created',\n",
    "              'dataset',\n",
    "              'file_status']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#afm.to_excel(\"duplicate_quality_metrics_06_13_2017.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by Experiment/File status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments = td[td.accession.isin(active_files_mismatch['accession'].values)]\\\n",
    "                        [['accession', 'dataset']].drop_duplicates('accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "active_files_mismatch['dataset'] = active_files_mismatch['accession']\\\n",
    "    .apply(lambda x: experiments[experiments.accession == x]['dataset'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "active_files_mismatch['@type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_ids = \"&@id=\".join(active_files_mismatch.dataset.unique())\n",
    "url = 'https://www.encodeproject.org/search/?type=Experiment&limit=all&@id={}'.format(search_ids)\n",
    "r = requests.get(url, auth=(key.authid, key.authpw))\n",
    "search_results = r.json()['@graph']\n",
    "search_id_map = {}\n",
    "for experiment in search_results:\n",
    "    search_id_map[experiment['@id']] = experiment['status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_files_mismatch['experiment_status'] = active_files_mismatch['dataset'].apply(lambda x: search_id_map[x])\n",
    "active_files_mismatch = active_files_mismatch.reset_index(drop=True)\n",
    "active_files_mismatch['dataset'] = active_files_mismatch['dataset'].apply(lambda x: x.replace(\"/experiments/\", \"\").replace(\"/\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_files_mismatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "active_files_mismatch[active_files_mismatch.expected_number < active_files_mismatch.actual_number].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "released_data = active_files_mismatch[~(active_files_mismatch.experiment_status.isin(['revoked',\n",
    "                                                                                      'deleted']))]\\\n",
    "                                                                                .groupby(['assay_term_name',\n",
    "                                                                                          'dataset',\n",
    "                                                                                          'accession',\n",
    "                                                                                          'assembly',\n",
    "                                                                                          'output_type',\n",
    "                                                                                          '@type',\n",
    "                                                                                          'expected_number',\n",
    "                                                                                          'actual_number',\n",
    "                                                                                          'experiment_status'])\\\n",
    "                                                                                 .count().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "released_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pull files with redundant audit flag from Idan's branch #4800, find consensus list (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull Idan's audit files\n",
    "url = 'https://4800-redundant-qc-6f1aa1cb5-idan.demo.encodedcc.org/search/'\\\n",
    "       '?type=File&audit.INTERNAL_ACTION.category=redundant+quality+metric&format=json&limit=all'\n",
    "r = requests.get(url, auth=(key.authid, key.authpw))\n",
    "search_results = r.json()['@graph']\n",
    "audit_flag = []\n",
    "for file in search_results:\n",
    "    audit_flag.append(file['accession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(audit_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af = pd.DataFrame(audit_flag)\n",
    "af = af.rename(columns={0:'accession'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = '0 ENCFF860EEZ 1 ENCFF806GBQ 2 ENCFF865OKF 3 ENCFF899TCQ 4 ENCFF011AMS 5 ENCFF414WJD 6 ENCFF663HVJ 7 ENCFF998PWW 8 ENCFF243AGG 9 ENCFF258AQQ 10 ENCFF709UWZ 11 ENCFF023KBS 12 ENCFF385ZPU 13 ENCFF619KWP 14 ENCFF767SOM 15 ENCFF948BIJ 16 ENCFF358RZK 17 ENCFF355CBE 18 ENCFF266EKT 19 ENCFF236AJI 20 ENCFF307AIG 21 ENCFF112PJJ 22 ENCFF694GJR 23 ENCFF591KID 24 ENCFF472SIB 25 ENCFF918TKF 26 ENCFF409NLS 27 ENCFF930IKU 28 ENCFF543CGB 29 ENCFF713UFE 30 ENCFF497JBZ 31 ENCFF496OJU 32 ENCFF278OYY 33 ENCFF526CXQ 34 ENCFF311KIP 35 ENCFF779CWH 36 ENCFF373UYA 37 ENCFF315SPJ 38 ENCFF548IHT 39 ENCFF484BSF 40 ENCFF899PSI 41 ENCFF713BDU 42 ENCFF193TFR 43 ENCFF211ZKG 44 ENCFF041ZEP 45 ENCFF220MHX 46 ENCFF077WNR 47 ENCFF283MNG 48 ENCFF896RNG 49 ENCFF970WRP 50 ENCFF659WGE 51 ENCFF281NFW 52 ENCFF491DDU 53 ENCFF137UAY 54 ENCFF896WQY 55 ENCFF950MBW 56 ENCFF900IQG 57 ENCFF384LXN 58 ENCFF865RQN 59 ENCFF071NEW 60 ENCFF476OYZ 61 ENCFF333VCK 62 ENCFF352PYL 63 ENCFF105VHD 64 ENCFF008RRH 65 ENCFF878BEQ 66 ENCFF078QRE 67 ENCFF150LTG 68 ENCFF576YJD 69 ENCFF501KQJ 70 ENCFF764BNL 71 ENCFF278QIG 72 ENCFF988FAL 73 ENCFF901ONA 74 ENCFF951FBF 75 ENCFF344UBE 76 ENCFF218LOB 77 ENCFF792ZKL 78 ENCFF435EIY 79 ENCFF960TDU 80 ENCFF549UEZ 81 ENCFF507RMK 82 ENCFF998KDQ 83 ENCFF312IYF 84 ENCFF811YFQ 85 ENCFF225TLP 86 ENCFF927TJR 87 ENCFF948MDE 88 ENCFF286YMB 89 ENCFF304XON 90 ENCFF375BIG 91 ENCFF365AWU 92 ENCFF093ZFB 93 ENCFF838BUR 94 ENCFF138SMJ 95 ENCFF032YPC 96 ENCFF689YCR 97 ENCFF540SLS 98 ENCFF546ZGF 99 ENCFF263EQX 100 ENCFF276EKT 101 ENCFF425KXW 102 ENCFF455EXR 103 ENCFF161QXX 104 ENCFF532MZI 105 ENCFF766SWF 106 ENCFF904CGH 107 ENCFF977MOV 108 ENCFF214OJW 109 ENCFF424FKL 110 ENCFF156XRJ 111 ENCFF437YIV 112 ENCFF435IEF 113 ENCFF349GID 114 ENCFF835RGX 115 ENCFF086IJA 116 ENCFF203ZIS 117 ENCFF534ULU 118 ENCFF909LKK 119 ENCFF784MKW 120 ENCFF248AGS 121 ENCFF488HDC 122 ENCFF217ISJ 123 ENCFF715NLX 124 ENCFF177LBB 125 ENCFF360MGZ 126 ENCFF801KEW 127 ENCFF884DZN 128 ENCFF566WGL 129 ENCFF374VWZ 130 ENCFF319FBU 131 ENCFF279MNV 132 ENCFF448YLM 133 ENCFF199LDJ 134 ENCFF323PIB 135 ENCFF148VQH 136 ENCFF485KSO 137 ENCFF362MSS 138 ENCFF562MPS 139 ENCFF505MGI 140 ENCFF731ZYR 141 ENCFF113DVJ 142 ENCFF198BFX 143 ENCFF388HRC 144 ENCFF731PDS 145 ENCFF378LGJ 146 ENCFF395BPD 147 ENCFF958MPB 148 ENCFF017LYR 149 ENCFF222DAU 150 ENCFF138WSJ 151 ENCFF245SEV 152 ENCFF051XIW 153 ENCFF407MVV 154 ENCFF152JZK 155 ENCFF121WOM 156 ENCFF304VVZ 157 ENCFF207ZRI 158 ENCFF743FCW 159 ENCFF015XIL 160 ENCFF531PVU 161 ENCFF257QND 162 ENCFF623CPY 163 ENCFF384SBC 164 ENCFF740RLD 165 ENCFF783LYO 166 ENCFF112YYK 167 ENCFF084FGO 168 ENCFF426JHB 169 ENCFF822NZG 170 ENCFF670GFY 171 ENCFF588PIS 172 ENCFF860JUD 173 ENCFF618GUI 174 ENCFF926JOK 175 ENCFF363HXH 176 ENCFF456PDQ 177 ENCFF056ESE 178 ENCFF728UAB 179 ENCFF808NFI 180 ENCFF256VYP 181 ENCFF843MEU 182 ENCFF549PGC 183 ENCFF585IAJ 184 ENCFF437YPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "z = [x.strip() for x in re.split('\\d* ', m) if x != '']\n",
    "z = pd.DataFrame(z).rename(columns={0:'accession'})\n",
    "af = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_files_mismatch = active_files_mismatch.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_files_mismatch.assay_term_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "afm = active_files_mismatch[active_files_mismatch.expected_number < active_files_mismatch.actual_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "afm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#af[~(af.accession.isin(afm.accession.values))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#afm[afm.accession.isin(af.accession.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "afm[afm.accession.isin(af.accession.values)]\\\n",
    "                 .sort_values(['assay_term_name', 'assembly'])\\\n",
    "                 .reset_index(drop=True) #.to_excel('redundant_qc_metrics_06_01_17.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af[(af.accession.isin(afm.accession.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afm[~(afm.accession.isin(af.accession.values))]\\\n",
    "                   .sort_values(['assay_term_name', 'assembly'])\\\n",
    "                   .reset_index(drop=True) #.to_excel(\"duplicate_but_different_05_31_2017.xlsx\")\n",
    "              \n",
    "ddbd = afm[~(afm.accession.isin(af.accession.values))]\\\n",
    "                   .sort_values(['assay_term_name', 'assembly'])\\\n",
    "                   .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "afm.assay_term_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all quality_metrics are same for each group of uuids in consensus list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only if af has been defined above\n",
    "both = afm[afm.accession.isin(af.accession.values)]\\\n",
    "                 .sort_values(['assay_term_name', 'assembly'])\\\n",
    "                 .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "both = afm.sort_values(['assay_term_name', 'assembly'])\\\n",
    "          .reset_index(drop=True)\n",
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(both.accession.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uuid = both.groupby(['assay_term_name',\n",
    "                      'accession',\n",
    "                      'output_type',\n",
    "                      '@type',\n",
    "                      'processing_stage',\n",
    "                      'expected_number',\n",
    "                      'actual_number',\n",
    "                      'qc_status',\n",
    "                      'uuid',\n",
    "                      'date_qc_created',\n",
    "                      'assembly',\n",
    "                      'analysis_name',\n",
    "                      'file_format',\n",
    "                      'date_file_created',\n",
    "                      'dataset',\n",
    "                      'file_status']).count()\\\n",
    "            .drop(['quality_metric_of',\n",
    "                   'metric_count'], axis=1)\\\n",
    "            .sort_index(level=[0, 1, 2, 3, 4, 9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uuid = both.merge(td,\n",
    "#            how='left',\n",
    "#            on=['accession',\n",
    "#                '@type',\n",
    "#                'assay_term_name',\n",
    "#                'analysis_name',\n",
    "#                'output_type',\n",
    "#                'assembly',\n",
    "#                'processing_stage'])\\\n",
    "#             .groupby(['assay_term_name',\n",
    "#                       'accession',\n",
    "#                       'output_type',\n",
    "#                       '@type',\n",
    "#                       'processing_stage',\n",
    "#                       'expected_number',\n",
    "#                       'actual_number',\n",
    "#                       'qc_status',\n",
    "#                       'uuid',\n",
    "#                       'date_qc_created',\n",
    "#                       'assembly',\n",
    "#                       'analysis_name',\n",
    "#                       'file_format',\n",
    "#                       'date_file_created',\n",
    "#                       'dataset',\n",
    "#                       'file_status']).count()\\\n",
    "#             .drop(['quality_metric_of',\n",
    "#                    'metric_count'], axis=1)\\\n",
    "#             .sort_index(level=[0, 1, 2, 3, 4, 9])#.to_excel(\"uuids_of_duplicate_metrics_06_01_2017.xlsx\")\n",
    "# uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuid_dict = uuid.reset_index().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Idan's redundant QC audit code.\n",
    "def audit_file_redundant_qc_metrics(quality_metrics):\n",
    "        metrics_set = set()\n",
    "        if quality_metrics:\n",
    "            redundant_types = set()\n",
    "            for metric in quality_metrics:\n",
    "                metric.pop('uuid', None)\n",
    "                metric.pop('@id', None)\n",
    "                metric.pop('date_created', None)\n",
    "                metric.pop('audit', None)\n",
    "                metric.pop('aliases', None)\n",
    "                metric.pop('attachment', None)\n",
    "                metric.pop('IDR_plot_true', None)\n",
    "                metric.pop('IDR_plot_rep1_pr', None)\n",
    "                metric.pop('IDR_plot_rep2_pr', None)\n",
    "                metric.pop('IDR_plot_pool_pr', None)\n",
    "                metric.pop('IDR_parameters_true', None)\n",
    "                metric.pop('IDR_parameters_rep1_pr', None)\n",
    "                metric.pop('IDR_parameters_rep2_pr', None)\n",
    "                metric.pop('IDR_parameters_pool_pr', None)\n",
    "                metric.pop('cross_correlation_plot', None)\n",
    "                metric.pop('quality_metric_of', None)\n",
    "                metric.pop('schema_version', None)\n",
    "                metric.pop('status', None)\n",
    "                metric.pop('step_run', None)\n",
    "                metric.pop('submitted_by', None)\n",
    "\n",
    "                metric_string = str(ordered_representation(metric))\n",
    "                if metric_string in metrics_set:\n",
    "                    redundant_types.add(metric['@type'][0])\n",
    "                else:\n",
    "                    metrics_set.add(metric_string)\n",
    "            return metrics_set\n",
    "\n",
    "def ordered_representation(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return sorted((k, ordered_representation(v)) for k, v in obj.items())\n",
    "    if isinstance(obj, list):\n",
    "        return sorted(ordered_representation(x) for x in obj)\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary grouped by accession, @type, and processing_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ugly code to create nested dictionary\n",
    "accession_grouped = defaultdict(list)\n",
    "for record in uuid_dict:\n",
    "    accession_grouped[record['accession']].append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accession_type_grouped = defaultdict(list)\n",
    "for k, v in accession_grouped.items():\n",
    "    type_grouped = defaultdict(list)\n",
    "    for record in v:\n",
    "        type_grouped[record['@type']].append(record)\n",
    "    accession_type_grouped[k].append(type_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accession_type_processing_grouped = defaultdict(list)\n",
    "for k, v in accession_type_grouped.items():\n",
    "    for x in v:\n",
    "        type_processing_grouped = defaultdict(list)\n",
    "        for i, y in x.items():\n",
    "            processing_stage = defaultdict(list)\n",
    "            for t in y:\n",
    "                processing_stage[t['processing_stage']].append(t)\n",
    "            type_processing_grouped[i].append(processing_stage)\n",
    "        accession_type_processing_grouped[k].append(type_processing_grouped)\n",
    "accession_type_processing_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab JSON for each QC object in group, print groups that are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate_but_different_accessions = []\n",
    "for k, v in accession_type_processing_grouped.items():\n",
    "    for x in v:\n",
    "        for i, y in x.items():\n",
    "            for t in y:\n",
    "                for p, d in t.items():\n",
    "                    expected_number = d[0]['expected_number']\n",
    "                    uuid_list = []\n",
    "                    for z in d:\n",
    "                        uuid_list.append(z['uuid'])\n",
    "                    uuids = '&uuid='.join(uuid_list)\n",
    "                    url = 'https://www.encodeproject.org/search/'\\\n",
    "                          '?type=QualityMetric&uuid={}&format=json'\\\n",
    "                          '&frame=embedded&limit=all'.format(uuids)\n",
    "                    r = requests.get(url, auth=(key.authid, key.authpw))\n",
    "                    search_results = r.json()['@graph']\n",
    "                    unique_metrics = audit_file_redundant_qc_metrics(search_results)\n",
    "                    if len(unique_metrics) != expected_number:\n",
    "                        duplicate_but_different_accessions.append((k, i, p))\n",
    "                        print(k)\n",
    "                        print(i)\n",
    "                        print(p)\n",
    "                        print()\n",
    "                        print(*unique_metrics, sep=\"\\n\\n\")\n",
    "                        print()\n",
    "                        print(\"Number of unique metrics: {}\".format(len(unique_metrics)))\n",
    "                        print(\"Expected number of metrics: {}\".format(expected_number))\n",
    "                        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(duplicate_but_different_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate_but_different_accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# duplicate_but_different = afm[(afm.accession.isin([x[0] for x in duplicate_but_different_accessions]))\n",
    "#    & (afm['@type'].isin([x[1] for x in duplicate_but_different_accessions]))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddbd2 = afm[(afm.accession.isin([x[0] for x in duplicate_but_different_accessions]))\n",
    "   & (afm['@type'].isin([x[1] for x in duplicate_but_different_accessions]))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddbd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([ddbd, ddbd2])\\\n",
    "    .sort_values('assay_term_name')\\\n",
    "    .reset_index(drop=True)\\\n",
    "    #.to_excel(\"duplicate_but_different_06_01_2017.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate_but_different\\\n",
    "    .sort_values('assay_term_name')\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .merge(td,\n",
    "           how='left',\n",
    "           on=['accession',\n",
    "               '@type',\n",
    "               'assay_term_name',\n",
    "               'analysis_name',\n",
    "               'output_type',\n",
    "               'assembly',\n",
    "               'processing_stage'])\\\n",
    "    .drop(['quality_metric_of',\n",
    "           'metric_count'], axis=1)\\\n",
    "    .sort_values(['accession',\n",
    "                  '@type',\n",
    "                  'date_qc_created'])\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .groupby(['assay_term_name',\n",
    "              'accession',\n",
    "              'output_type',\n",
    "              '@type',\n",
    "              'processing_stage',\n",
    "              'expected_number',\n",
    "              'actual_number',\n",
    "              'qc_status',\n",
    "              'uuid',\n",
    "              'date_qc_created',\n",
    "              'assembly',\n",
    "              'analysis_name',\n",
    "              'file_format',\n",
    "              'date_file_created',\n",
    "              'dataset',\n",
    "              'file_status']).count()\\\n",
    "        .sort_index(level=[0, 1, 2, 3, 4, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([ddbd, ddbd2])\\\n",
    "    .sort_values('assay_term_name')\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .merge(td,\n",
    "           how='left',\n",
    "           on=['accession',\n",
    "               '@type',\n",
    "               'assay_term_name',\n",
    "               'analysis_name',\n",
    "               'output_type',\n",
    "               'assembly',\n",
    "               'processing_stage'])\\\n",
    "    .drop(['quality_metric_of',\n",
    "           'metric_count'], axis=1)\\\n",
    "    .sort_values(['accession',\n",
    "                  '@type',\n",
    "                  'date_qc_created'])\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .groupby(['assay_term_name',\n",
    "              'accession',\n",
    "              'output_type',\n",
    "              '@type',\n",
    "              'processing_stage',\n",
    "              'expected_number',\n",
    "              'actual_number',\n",
    "              'qc_status',\n",
    "              'uuid',\n",
    "              'date_qc_created',\n",
    "              'assembly',\n",
    "              'analysis_name',\n",
    "              'file_format',\n",
    "              'date_file_created',\n",
    "              'dataset',\n",
    "              'file_status']).count()\\\n",
    "        .sort_index(level=[0, 1, 2, 3, 4, 9])#.to_excel(\"duplicate_but_different_grouped_06_02_2017.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtract detected duplicate but different rows from consensus list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(both.accession.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddbd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus = both[~((both.accession.isin(ddbd2.accession.values))\\\n",
    "                 & (both['@type'].isin(ddbd2['@type'].values)))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Experiment to Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_uuids = both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_ids = \"&@id=\".join(consensus_uuids.dataset.unique())\n",
    "url = 'https://www.encodeproject.org/search/'\\\n",
    "      '?type=Experiment&limit=all&frame=embedded&@id={}'.format(search_ids)\n",
    "r = requests.get(url, auth=(key.authid, key.authpw))\n",
    "search_results = r.json()['@graph']\n",
    "search_id_map = {}\n",
    "for experiment in search_results:\n",
    "    search_id_map[experiment['@id']] = experiment['lab']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids['experiment_lab'] = consensus_uuids.dataset.apply(lambda x: search_id_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids.drop_duplicates('accession', keep='first').experiment_lab.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Lab to wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab_wrangler_lookup = {\n",
    "    \"bradley-bernstein\": \"Cricket\",\n",
    "    \"michael-snyder\": \"Jason\",\n",
    "    \"richard-myers\": \"Carrie\",\n",
    "    \"john-stamatoyannopoulos\": \"Jason\",\n",
    "    \"peggy-farnham\": \"Esther\",\n",
    "    \"brenton-graveley\": \"Kath\",\n",
    "    \"bing-ren\": \"Kath\",\n",
    "    \"xiang-dong-fu\": \"Kath\",\n",
    "    \"will-greenleaf\": \"Jason\",\n",
    "    \"kevin-white\": \"Esther\",\n",
    "    \"barbara-wold\": \"Aditi\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids['wrangler'] = consensus_uuids.experiment_lab\\\n",
    "                                    .apply(lambda x: lab_wrangler_lookup.get(x, 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids.drop_duplicates('accession', keep='first').wrangler.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "## Pull all file attachment names and md5sums for duplicate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids['@type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Possible atachments as defined in schema.\n",
    "quality_attachments = {\n",
    "    'IDRQualityMetric': ['IDR_plot_true',\n",
    "                         'IDR_plot_rep1_pr',\n",
    "                         'IDR_plot_rep2_pr',\n",
    "                         'IDR_plot_pool_pr',\n",
    "                         'IDR_parameters_true',\n",
    "                         'IDR_parameters_rep1_pr',\n",
    "                         'IDR_parameters_rep2_pr',\n",
    "                         'IDR_parameters_pool_pr'],\n",
    "    'ChipSeqFilterQualityMetric': ['cross_correlation_plot',\n",
    "                                   'attachment'],\n",
    "    'SamtoolsFlagstatsQualityMetric': ['attachment'],\n",
    "    'StarQualityMetric': ['attachment'],\n",
    "    'GenericQualityMetric': ['attachment'],\n",
    "    'ComplexityXcorrQualityMetric': ['cross_correlation_plot',\n",
    "                                     'attachment']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '&accession='.join(consensus_uuids.accession.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.encodeproject.org/'\\\n",
    "            'search/?type=File&accession={}'\\\n",
    "            '&frame=embedded&format=json&limit=all'.format(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(url, auth=(key.authid, key.authpw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = r.json()['@graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "error_log = []\n",
    "for result in results:\n",
    "    for metric in result['quality_metrics']:\n",
    "        uuid = metric['uuid']\n",
    "        metric_type = metric['@type'][0]\n",
    "        for possible_attachment in quality_attachments[metric_type]:\n",
    "            try:\n",
    "                records.append((uuid,\n",
    "                               metric_type,\n",
    "                               possible_attachment,\n",
    "                               metric[possible_attachment]['download'],\n",
    "                               metric[possible_attachment]['md5sum']))\n",
    "            except KeyError:\n",
    "                records.append((uuid,\n",
    "                               metric_type,\n",
    "                               possible_attachment,\n",
    "                               'no_value',\n",
    "                               'no_value'))\n",
    "                error_log.append(\"{} has no attachment of type {}.\".format(metric_type,\n",
    "                                                                           possible_attachment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attachment_details = pd.DataFrame(records).rename(columns={0: \"uuid\",\n",
    "                                                           1: \"@type\",\n",
    "                                                           2: \"attachment_field\",\n",
    "                                                           3: \"attachment_name\",\n",
    "                                                           4: \"attachment_md5\"})\n",
    "\n",
    "attachment_details = attachment_details[(attachment_details.uuid.isin(consensus_uuids.uuid.values))]\\\n",
    "                                                                              .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(attachment_details.uuid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(consensus_uuids.uuid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids[consensus_uuids.uuid.isin(attachment_details.uuid.values)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attachment_details.attachment_field.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attachment_details.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc = consensus_uuids.merge(attachment_details,\n",
    "                      how='left',\n",
    "                      on=['uuid', '@type']).groupby(['assay_term_name',\n",
    "                                                     'wrangler',\n",
    "                                                     'experiment_lab',\n",
    "                                                     'accession',\n",
    "                                                     'output_type',\n",
    "                                                     '@type',\n",
    "                                                     'processing_stage',\n",
    "                                                     'expected_number',\n",
    "                                                     'actual_number',\n",
    "                                                     'attachment_field',\n",
    "                                                     'qc_status',\n",
    "                                                     'uuid',\n",
    "                                                     'date_qc_created',\n",
    "                                                     'attachment_name',\n",
    "                                                     'attachment_md5',\n",
    "                                                     'assembly',\n",
    "                                                     'analysis_name',\n",
    "                                                     'file_format',\n",
    "                                                     'date_file_created',\n",
    "                                                     'dataset',\n",
    "                                                     'file_status']).count()\\\n",
    "                                            .sort_index(level=[0, 1, 2, 3, 4, 5, 6, 9, 12, 13, 14])#.to_excel(\"duplicate_metrics_no_value_06_05_2017.xlsx\")\n",
    "cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick most recent UUIDs with attachments to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_recent_uuid_with_attachment(uuid_group):\n",
    "    \"\"\"Returns most recent quality metric uuid\n",
    "    with a valid attachment MD5sum, given a sorted\n",
    "    group of otherwise redundant metrics. If all\n",
    "    attachments are missing (no_value) then the\n",
    "    most recent uuid will be returned.\"\"\"\n",
    "    uuid_to_keep = None\n",
    "    # Pick most recent uuid with attachment.\n",
    "    for metric in uuid_group[::-1]:\n",
    "        if uuid_to_keep:\n",
    "            break\n",
    "        if metric[4] != 'no_value':\n",
    "            uuid_to_keep = metric[1]\n",
    "    # If attachemnt missing for all uuids\n",
    "    # then pick most recent.\n",
    "    if not uuid_to_keep:\n",
    "        uuid_to_keep = uuid_group[-1][1]\n",
    "    return uuid_to_keep\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose uuid to keep based on date and attachment existing.\n",
    "uuids_attachments = cc.reset_index().sort_values(['accession',\n",
    "                                                  '@type',\n",
    "                                                  'date_qc_created']).reset_index(drop=True)\n",
    "uuids_to_keep = []\n",
    "for accession in uuids_attachments.accession.unique():\n",
    "    # Pull DataFrame records for each accession.\n",
    "    selected_rows = uuids_attachments[uuids_attachments.accession == accession]\n",
    "    metric_types = selected_rows['@type'].unique()\n",
    "    for metric_type in metric_types:\n",
    "        processing_stages = selected_rows[selected_rows['@type'] == metric_type]\\\n",
    "                                                    ['processing_stage'].unique()\n",
    "        for processing_stage in processing_stages:\n",
    "            attachment_types = selected_rows[(selected_rows['@type'] == metric_type)\n",
    "                                             & (selected_rows['processing_stage'] == processing_stage)]\\\n",
    "                                                                           ['attachment_field'].unique()\n",
    "            uuid_set = set()\n",
    "            for attachment_type in attachment_types:\n",
    "                uuid_group = selected_rows[(selected_rows['@type'] == metric_type)\n",
    "                                           & (selected_rows['processing_stage'] == processing_stage)\n",
    "                                           & (selected_rows['attachment_field'] == attachment_type)]\\\n",
    "                                          .sort_values('date_qc_created')[['uuid',\n",
    "                                                                           'date_qc_created',\n",
    "                                                                           'qc_status',\n",
    "                                                                           'attachment_md5']]\\\n",
    "                                                                  .reset_index(drop=True)\\\n",
    "                                                                  .to_records()\n",
    "                uuid_set.add(most_recent_uuid_with_attachment(uuid_group))\n",
    "            if len(uuid_set) == 1:\n",
    "                uuids_to_keep.append(list(uuid_set)[0])\n",
    "            else:\n",
    "                raise ValueError('Different attachment fields between metrics.'\n",
    "                                 ' Conflicting uuids: {}'.format(uuid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utk = pd.DataFrame(pd.DataFrame(list(set(uuids_to_keep))))\n",
    "utk['action'] = 'keep'\n",
    "utk = utk.rename(columns={0:'uuid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Proposed action.\n",
    "action_proposed = consensus_uuids.merge(attachment_details,\n",
    "                                       how='left', on=['uuid','@type'])\\\n",
    "                                .merge(utk,\n",
    "                                        how=\"left\",\n",
    "                                        on=['uuid'])\\\n",
    "                                        .fillna(\"delete\")\\\n",
    "                                        .groupby(['assay_term_name',\n",
    "                                                  'wrangler',\n",
    "                                                  'experiment_lab',\n",
    "                                                  'accession',\n",
    "                                                  'output_type',\n",
    "                                                  '@type',\n",
    "                                                  'processing_stage',\n",
    "                                                  'expected_number',\n",
    "                                                  'actual_number',\n",
    "                                                  'attachment_field',\n",
    "                                                  'qc_status',\n",
    "                                                  'action',\n",
    "                                                  'uuid',\n",
    "                                                  'date_qc_created',\n",
    "                                                  'attachment_name',\n",
    "                                                  'attachment_md5',\n",
    "                                                  'assembly',\n",
    "                                                  'analysis_name',\n",
    "                                                  'file_format',\n",
    "                                                  'date_file_created',\n",
    "                                                  'dataset',\n",
    "                                                  'file_status']).count()\\\n",
    "                                    .sort_index(level=[0, 1, 2, 3, 4, 5, 6, 9, 13, 14])\n",
    "action_proposed#.to_excel('delete_keep_all_pipelines_06_06_2017.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove specific accessions dealt with by wrangers and create lists of UUIDs to keep and delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "action_proposed_flat = action_proposed.reset_index()\n",
    "action_proposed_flat = consensus_uuids.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove metrics Esther has to decide.\n",
    "action_proposed_flat = action_proposed_flat[~(action_proposed_flat.accession.isin(['ENCFF245SEV',\n",
    "                                                                                   'ENCFF808NFI']))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove metric Seth fixed.\n",
    "action_proposed_flat = action_proposed_flat[~(action_proposed_flat.accession == 'ENCFF156XRJ')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuids_to_keep = action_proposed_flat[action_proposed_flat.action == \"keep\"].uuid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuids_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(uuids_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuids_to_delete = action_proposed_flat[action_proposed_flat.action == \"delete\"].uuid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(uuids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure no overlap between lists.\n",
    "set(uuids_to_keep).intersection(set(uuids_to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuids_to_keep = pd.DataFrame(uuids_to_keep)\n",
    "uuids_to_delete = pd.DataFrame(uuids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuids_to_keep['status'] = \"released\"\n",
    "uuids_to_delete['status'] = \"deleted\"\n",
    "uuids_to_keep = uuids_to_keep.rename(columns={0: \"uuid\"})\n",
    "uuids_to_delete = uuids_to_delete.rename(columns={0: \"uuid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuids_to_keep.to_csv(\"../../uuids_to_keep_06_28_2017.tsv\", sep=\"\\t\", index=False)\n",
    "uuids_to_delete.to_csv(\"../../uuids_to_delete_06_28_2017.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group quality_metrics by accession, type, processing_stage, and attachment field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc_dict = cc.reset_index().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_dict = action_proposed_flat.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ugly code to create nested dictionary\n",
    "accession_grouped = defaultdict(list)\n",
    "for record in cc_dict:\n",
    "    accession_grouped[record['accession']].append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accession_type_grouped = defaultdict(list)\n",
    "for k, v in accession_grouped.items():\n",
    "    type_grouped = defaultdict(list)\n",
    "    for record in v:\n",
    "        type_grouped[record['@type']].append(record)\n",
    "    accession_type_grouped[k].append(type_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accession_type_processing_grouped = defaultdict(list)\n",
    "for k, v in accession_type_grouped.items():\n",
    "    for x in v:\n",
    "        type_processing_grouped = defaultdict(list)\n",
    "        for i, y in x.items():\n",
    "            processing_stage = defaultdict(list)\n",
    "            for t in y:\n",
    "                processing_stage[t['processing_stage']].append(t)\n",
    "            type_processing_grouped[i].append(processing_stage)\n",
    "        accession_type_processing_grouped[k].append(type_processing_grouped)\n",
    "#accession_type_processing_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accession_type_processing_attachment_grouped = defaultdict(list)\n",
    "for k, v in accession_type_processing_grouped.items():\n",
    "    for x in v:\n",
    "        type_processing_attachment_grouped = defaultdict(list)\n",
    "        for o, q in x.items():\n",
    "            for b in q:\n",
    "                processing_attachment_grouped = defaultdict(list)\n",
    "                for i, y in b.items():\n",
    "                    attachment_field = defaultdict(list)\n",
    "                    for t in y:\n",
    "                        attachment_field[t['attachment_field']].append(t)\n",
    "                    processing_attachment_grouped[i].append(attachment_field)\n",
    "                type_processing_attachment_grouped[o].append(processing_attachment_grouped)\n",
    "    accession_type_processing_attachment_grouped[k].append(type_processing_attachment_grouped)\n",
    "#accession_type_processing_attachment_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for different MD5sums/filenames of attachments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicate_but_different_info = []\n",
    "accession_list = []\n",
    "for k, v in accession_type_processing_attachment_grouped.items():\n",
    "    for x in v:\n",
    "        for i, y in x.items():\n",
    "            for t in y:\n",
    "                for w, r in t.items():\n",
    "                    for u in r:\n",
    "                        for p, d in u.items():\n",
    "                            expected_number = d[0]['expected_number']\n",
    "                            attachment_name_set = set()\n",
    "                            attachment_md5_set = set()\n",
    "                            metric_info = []\n",
    "                            for z in d:\n",
    "                                attachment_name_set.add(z['attachment_name'])\n",
    "                                attachment_md5_set.add(z['attachment_md5'])\n",
    "                                metric_info.append((z['uuid'],\n",
    "                                                    z['attachment_name'],\n",
    "                                                    z['attachment_md5'],\n",
    "                                                    z['qc_status'],\n",
    "                                                    z['file_status']))\n",
    "                            if (len(attachment_md5_set) > 1):\n",
    "                                print(\"MD5sums do not match.\")\n",
    "                                print(\"Kind:\", end=' ')\n",
    "                                accession_list.append(k)\n",
    "                                print(k, i, w, p)\n",
    "                                print(\"Number duplicates: {}\".format(len(d)))\n",
    "                                print(\"Items in group:\")\n",
    "                                for h, e in enumerate(metric_info):\n",
    "                                    print(h, end=\": \")\n",
    "                                    print(e)\n",
    "                                print(\"Filename set:\")\n",
    "                                print(attachment_name_set)\n",
    "                                print(\"Md5sum set:\")\n",
    "                                print(attachment_md5_set)\n",
    "                                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(action_proposed_flat.accession.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different MD5sums\n",
    "len(accession_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different surface values\n",
    "len(duplicate_but_different.accession.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick duplicate_but_different uuids to keep/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose uuid to keep based on date and attachment existing.\n",
    "uuids_attachments = dd.reset_index().sort_values(['accession',\n",
    "                                                  '@type',\n",
    "                                                  'date_qc_created']).reset_index(drop=True)\n",
    "uuids_to_keep = []\n",
    "for accession in uuids_attachments.accession.unique():\n",
    "    # Pull DataFrame records for each accession.\n",
    "    selected_rows = uuids_attachments[uuids_attachments.accession == accession]\n",
    "    metric_types = selected_rows['@type'].unique()\n",
    "    for metric_type in metric_types:\n",
    "        processing_stages = selected_rows[selected_rows['@type'] == metric_type]\\\n",
    "                                                    ['processing_stage'].unique()\n",
    "        uuid_set = set()\n",
    "        for processing_stage in processing_stages:\n",
    "           \n",
    "            uuid_group = selected_rows[(selected_rows['@type'] == metric_type)\n",
    "                                       & (selected_rows['processing_stage'] == processing_stage)]\\\n",
    "                                      .sort_values('date_qc_created')[['uuid',\n",
    "                                                                       'date_qc_created',\n",
    "                                                                       'qc_status']]\\\n",
    "                                                              .reset_index(drop=True)\\\n",
    "                                                              .to_records()\n",
    "            uuid_set.add(uuid_group[-1][1])\n",
    "            if len(uuid_set) == 1:\n",
    "                uuids_to_keep.append(list(uuid_set)[0])\n",
    "            else:\n",
    "                raise ValueError('Different attachment fields between metrics.'\n",
    "                                 ' Conflicting uuids: {}'.format(uuid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dduuids_to_keep = pd.DataFrame(uuids_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dduuids_to_keep['status'] = 'released'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dduuids_to_keep = dduuids_to_keep.rename(columns={0: 'uuid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dd = dd.reset_index().merge(dduuids_to_keep, how='left', on='uuid').fillna('deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove ones Seth fixed and remove RNA\n",
    "dd = dd[~(dd.dataset.isin(['/experiments/ENCSR000EGT/', '/experiments/ENCSR000EGU/']))\n",
    "   & ~(dd.assay_term_name==\"shRNA knockdown followed by RNA-seq\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dd.groupby(['assay_term_name',\n",
    "          'dataset',\n",
    "          'accession',\n",
    "          'output_type',\n",
    "          '@type',\n",
    "          'processing_stage',\n",
    "          'expected_number',\n",
    "          'actual_number',\n",
    "          'qc_status',\n",
    "          'status',\n",
    "          'uuid',\n",
    "          'date_qc_created',\n",
    "          'assembly',\n",
    "          'analysis_name',\n",
    "          'file_format',\n",
    "          'date_file_created',\n",
    "          'file_status']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_uuids_to_keep = pd.DataFrame(dd[dd.status=='released'].uuid.unique())\n",
    "dd_uuids_to_keep['status'] = 'released'\n",
    "dd_uuids_to_keep = dd_uuids_to_keep.rename(columns={0: 'uuid'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_uuids_to_delete = pd.DataFrame(dd[dd.status=='deleted'].uuid.unique())\n",
    "dd_uuids_to_delete['status'] = 'deleted'\n",
    "dd_uuids_to_delete = dd_uuids_to_delete.rename(columns={0: 'uuid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_uuids_to_keep.to_csv(\"dd_uuids_to_keep_06_13_2017.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_uuids_to_delete.to_csv(\"dd_uuids_to_delete_06_13_2017.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch uuids by experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_values = action_proposed_flat.dataset.unique()\n",
    "for i in range(0, len(exp_values), 10):\n",
    "    batch = exp_values[i:i+10]\n",
    "    data = action_proposed_flat[action_proposed_flat.dataset.isin(batch)]\\\n",
    "                                                        .groupby(['dataset',\n",
    "                                                                  'action',\n",
    "                                                                  'uuid']).count()[[]].reset_index()\n",
    "    data_to_keep = data[data.action==\"keep\"]\n",
    "    data_to_delete = data[data.action==\"delete\"]\n",
    "    uuids_to_keep = pd.DataFrame(data_to_keep.uuid.unique())\n",
    "    uuids_to_delete = pd.DataFrame(data_to_delete.uuid.unique())\n",
    "    uuids_to_keep['status'] = \"released\"\n",
    "    uuids_to_delete['status'] = \"deleted\"\n",
    "    uuids_to_keep = uuids_to_keep.rename(columns={0: \"uuid\"})\n",
    "    uuids_to_delete = uuids_to_delete.rename(columns={0: \"uuid\"})\n",
    "    print(i)\n",
    "    print(uuids_to_keep.shape)\n",
    "    print(uuids_to_delete.shape)\n",
    "    print(batch)\n",
    "#     uuids_to_keep.to_csv(\"patch_batch/uuids_to_keep_06_13_2017_batch_{}.tsv\".format(i),\n",
    "#                          sep=\"\\t\",\n",
    "#                          index=False)\n",
    "#     uuids_to_delete.to_csv(\"patch_batch/uuids_to_delete_06_13_2017_batch_{}.tsv\".format(i),\n",
    "#                            sep=\"\\t\",\n",
    "#                            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consensus_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td[\"date_qc_created\"] = td[\"date_qc_created\"].apply(lambda x: pd.to_datetime(x))\n",
    "action_all = td\n",
    "action_all['action'] = 'keep'\n",
    "action_all['audit'] = 'unique'\n",
    "action_all = action_all.sort_values(\"assay_term_name\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_proposed_flat = action_proposed.reset_index()\n",
    "apf = action_proposed_flat[['uuid', 'action', 'actual_number']].reset_index(drop=True)\n",
    "apf['audit'] = 'duplicate'\n",
    "action_all = td.merge(apf, how='left', on=['uuid'])\n",
    "action_all['action'] = action_all['action'].fillna('keep')\n",
    "action_all['audit'] = action_all['audit'].fillna('unique')\n",
    "action_all['actual_number'] = action_all['actual_number'].fillna(1)\n",
    "aad = action_all[action_all.audit==\"duplicate\"].reset_index(drop=True)\n",
    "aau = action_all[action_all.audit==\"unique\"].reset_index(drop=True)\n",
    "action_all = action_all.sort_values(\"assay_term_name\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set(style=\"ticks\", font=\"Lato\")\n",
    "import datetime\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[12, 15])\n",
    "    sns.stripplot(x=\"date_qc_created\",\n",
    "                  y=\"assay_term_name\",\n",
    "                  hue=\"audit\",\n",
    "                  data=action_all,\n",
    "                  size=15,\n",
    "                  jitter=True,\n",
    "                  split=True,\n",
    "                  palette=sns.color_palette([\"black\",\n",
    "                                             \"#de2d26\"]),\n",
    "                  alpha=0.3)\n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    edge_color = x.get_facecolor()\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(edge_color)\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True,bottom=True)\n",
    "fig.gca().xaxis.grid(True, ls='--')\n",
    "fig.gca().yaxis.grid(True, ls=\"--\")\n",
    "bottom, top = fig.gca().get_ylim()\n",
    "\n",
    "for x in np.arange(top, bottom + 1, 1):\n",
    "    fig.gca().axhline(x,\n",
    "                      color=\"black\",\n",
    "                      linewidth=1)\n",
    "    \n",
    "fig.gca().set_ylim([top - 0.1, bottom + 0.1])\n",
    "box = fig.gca().get_position()\n",
    "fig.gca().set_position([box.x0,\n",
    "                        box.y0,\n",
    "                        box.width * 0.85,\n",
    "                        box.height])\n",
    "\n",
    "sns.plt.legend(loc=\"upper left\",\n",
    "               bbox_to_anchor=(1, 0.5),\n",
    "               frameon=True,\n",
    "               prop={'size':'x-large'})\n",
    "\n",
    "sns.plt.title('Quality Metrics by Assay and Date (After Patching)',\n",
    "              size=16,\n",
    "              fontweight='bold');\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "fig.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_all[action_all.audit=='duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order data by date_qc_created and\n",
    "# and convert field to string for visualization.\n",
    "td = td.sort_values(\"date_qc_created\").reset_index(drop=True)\n",
    "td[\"date_qc_created\"] = td[\"date_qc_created\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_proposed_flat = action_proposed.reset_index()\n",
    "apf = action_proposed_flat[['uuid', 'action', 'actual_number']].reset_index(drop=True)\n",
    "apf['audit'] = 'duplicate'\n",
    "action_all = td.merge(apf, how='left', on=['uuid'])\n",
    "action_all['action'] = action_all['action'].fillna('keep')\n",
    "action_all['audit'] = action_all['audit'].fillna('unique')\n",
    "action_all['actual_number'] = action_all['actual_number'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aad = action_all[action_all.audit==\"duplicate\"].reset_index(drop=True)\n",
    "aau = action_all[action_all.audit==\"unique\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_all = action_all.sort_values(\"assay_term_name\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set(style=\"ticks\", font=\"Lato\")\n",
    "import datetime\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[12, 15])\n",
    "    sns.stripplot(x=\"date_qc_created\",\n",
    "                  y=\"assay_term_name\",\n",
    "                  hue=\"audit\",\n",
    "                  data=action_all,\n",
    "                  size=15,\n",
    "                  jitter=True,\n",
    "                  split=True,\n",
    "                  palette=sns.color_palette([\"black\",\n",
    "                                             \"#de2d26\"]),\n",
    "                  alpha=0.3)\n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    edge_color = x.get_facecolor()\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(edge_color)\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True,bottom=True)\n",
    "fig.gca().xaxis.grid(True, ls='--')\n",
    "fig.gca().yaxis.grid(True, ls=\"--\")\n",
    "bottom, top = fig.gca().get_ylim()\n",
    "\n",
    "for x in np.arange(top, bottom + 1, 1):\n",
    "    fig.gca().axhline(x,\n",
    "                      color=\"black\",\n",
    "                      linewidth=1)\n",
    "    \n",
    "fig.gca().set_ylim([top - 0.1, bottom + 0.1])\n",
    "box = fig.gca().get_position()\n",
    "fig.gca().set_position([box.x0,\n",
    "                        box.y0,\n",
    "                        box.width * 0.85,\n",
    "                        box.height])\n",
    "\n",
    "sns.plt.legend(loc=\"upper left\",\n",
    "               bbox_to_anchor=(1, 0.5),\n",
    "               frameon=True,\n",
    "               prop={'size':'x-large'})\n",
    "\n",
    "sns.plt.title('Quality Metrics by Assay and Date (Before Patching)',\n",
    "              size=16,\n",
    "              fontweight='bold');\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "fig.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "action_all[action_all['assay_term_name'] == \"ATAC-seq\"].audit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set(style=\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    sns.stripplot(x=\"actual_number\",\n",
    "                  y=\"assay_term_name\",\n",
    "                  hue=\"audit\",\n",
    "                  data=action_all,\n",
    "                  size=15,\n",
    "                  #edgecolor=\"black\",\n",
    "                  palette=sns.color_palette([\"gray\",\n",
    "                                             \"#de2d26\",\n",
    "                                             #\"#95a5a6\",\n",
    "                                             #\"#e41a1c\",\n",
    "                                             #\"#a6cee3\",\n",
    "                                             \"black\",\n",
    "                                             \"#e74c3c\",\n",
    "                                             \"#34495e\",\n",
    "                                             \"#3498db\",\n",
    "                                             \"#2ecc71\"]),\n",
    "                  jitter=True,\n",
    "                  alpha=0.9)\n",
    "\n",
    "\n",
    "fig.gca().set_xticks([x for x in sorted(action_all.actual_number.unique())])\n",
    "\n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    edge_color = x.get_facecolor()\n",
    "    x.set_facecolor(\"None\")\n",
    "    x.set_edgecolor(edge_color)\n",
    "    x.set_linewidth(0.15)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "\n",
    "for x in fig.gca().legend_.__dict__['legendHandles']:\n",
    "    x.set_linewidth(1)\n",
    "    x.set_alpha(1)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set(style=\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    sns.stripplot(x=\"metric_count\",\n",
    "                  y=\"file_status\",\n",
    "                  hue=\"qc_status\",\n",
    "                  order=['released',\n",
    "                         'in progress',\n",
    "                         'archived',\n",
    "                         'replaced',\n",
    "                         'revoked',\n",
    "                         'deleted',\n",
    "                         'content error'],\n",
    "                  data=td,\n",
    "                  size=15,\n",
    "                  #edgecolor=\"black\",\n",
    "                  palette=sns.color_palette([\"black\",\n",
    "                                             \"#de2d26\",\n",
    "                                             #\"#95a5a6\",\n",
    "                                             #\"#e41a1c\",\n",
    "                                             #\"#a6cee3\",\n",
    "                                             \"black\",\n",
    "                                             \"#e74c3c\",\n",
    "                                             \"#34495e\",\n",
    "                                             \"#3498db\",\n",
    "                                             \"#2ecc71\"]),\n",
    "                  jitter=True,\n",
    "                  alpha=0.3)\n",
    "\n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    edge_color = x.get_facecolor()\n",
    "    x.set_facecolor(\"None\")\n",
    "    x.set_edgecolor(edge_color)\n",
    "    x.set_linewidth(0.05)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "\n",
    "for x in fig.gca().legend_.__dict__['legendHandles']:\n",
    "    x.set_linewidth(1)\n",
    "    x.set_alpha(1)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "if td[\"date_qc_created\"].dtype == \"<M8[ns]\":\n",
    "    pass\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.4):\n",
    "    fig = plt.figure(figsize=[7, 7])\n",
    "    sns.stripplot(x=\"metric_count\",\n",
    "                  y=\"date_qc_created\",\n",
    "                  data=td,\n",
    "                  size=4,\n",
    "                  edgecolor=\"black\",\n",
    "                  jitter=True)\n",
    "    \n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(\"black\")\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)\n",
    "fig.gca().tick_params(labelbottom='on',\n",
    "                      labeltop='on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    sns.stripplot(x=\"metric_count\",\n",
    "                  y=\"assay_term_name\",\n",
    "                  data=td,\n",
    "                  size=15,\n",
    "                  edgecolor=\"black\",\n",
    "                  jitter=True)\n",
    "    \n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(\"black\")\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    sns.stripplot(x=\"metric_count\",\n",
    "                  y=\"@type\",\n",
    "                  data=td,\n",
    "                  size=15,\n",
    "                  edgecolor=\"black\",\n",
    "                  jitter=True)\n",
    "    \n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(\"black\")\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    sns.stripplot(x=\"metric_count\",\n",
    "                  y=\"output_type\",\n",
    "                  data=td,\n",
    "                  size=15,\n",
    "                  edgecolor=\"black\",\n",
    "                  jitter=True)\n",
    "    \n",
    "for x in fig.gca().findobj(mpl.collections.PathCollection):\n",
    "    x.set_facecolor(\"white\")\n",
    "    x.set_edgecolor(\"black\")\n",
    "    x.set_linewidth(1.5)\n",
    "    x.set_snap(False)\n",
    "    x.set_antialiased(True)\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.gca().xaxis.grid(True)\n",
    "fig.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[14, 8])\n",
    "    sns.boxplot(x=\"file_format\",\n",
    "                y=\"metric_count\",\n",
    "                data=td,\n",
    "                color=\"black\")\n",
    "\n",
    "    for i, y in enumerate(fig.gca().artists):\n",
    "        y.set_facecolor(\"None\")\n",
    "        #y.set_edgecolor(\"black\")\n",
    "        #for line in fig.gca().lines:\n",
    "            #line.set_color(\"red\")\n",
    "            #line.set_mfc(\"red\")\n",
    "            #line.set_mec(\"red\")\n",
    "    #sns.despine(ax=fig.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1):\n",
    "    fig = plt.figure(figsize=[14, 8])\n",
    "    sns.boxplot(x=\"assembly\",\n",
    "                y=\"metric_count\",\n",
    "                data=td,\n",
    "                color=\"black\")\n",
    "\n",
    "    for i, y in enumerate(fig.gca().artists):\n",
    "        y.set_facecolor(\"None\")\n",
    "        #y.set_edgecolor(\"black\")\n",
    "        #for line in fig.gca().lines:\n",
    "            #line.set_color(\"red\")\n",
    "            #line.set_mfc(\"red\")\n",
    "            #line.set_mec(\"red\")\n",
    "    #sns.despine(ax=fig.gca())\n",
    "#fig.get_dpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[14, 8])\n",
    "    sns.boxplot(x=\"file_status\",\n",
    "                y=\"metric_count\",\n",
    "                data=td,\n",
    "                color=\"black\")\n",
    "\n",
    "    for i, y in enumerate(fig.gca().artists):\n",
    "        y.set_facecolor(\"None\")\n",
    "        #y.set_edgecolor(\"black\")\n",
    "        #for line in fig.gca().lines:\n",
    "            #line.set_color(\"red\")\n",
    "            #line.set_mfc(\"red\")\n",
    "            #line.set_mec(\"red\")\n",
    "    #sns.despine(ax=fig.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.dpi'] = 72\n",
    "sns.set_style(\"ticks\")\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    fig = plt.figure(figsize=[14, 8])\n",
    "    sns.boxplot(x=\"qc_status\",\n",
    "                y=\"metric_count\",\n",
    "                data=td,\n",
    "                color=\"black\")\n",
    "\n",
    "    for i, y in enumerate(fig.gca().artists):\n",
    "        y.set_facecolor(\"None\")\n",
    "        #y.set_edgecolor(\"black\")\n",
    "        #for line in fig.gca().lines:\n",
    "            #line.set_color(\"red\")\n",
    "            #line.set_mfc(\"red\")\n",
    "            #line.set_mec(\"red\")\n",
    "    #sns.despine(ax=fig.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('replaced_items_no_redirect_06_12_2017.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.accession=='ENCFF008MOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[(df.content_md5sum_old == df.content_md5sum_new)\n",
    "   & (df.content_md5sum_old == 'not_available')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
