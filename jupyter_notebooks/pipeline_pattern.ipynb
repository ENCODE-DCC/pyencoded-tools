{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import operator\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from functools import wraps\n",
    "from itertools import chain\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied from pyencoded-tools/encodedcc.py to avoid dependency.\n",
    "class ENC_Key:\n",
    "    def __init__(self, keyfile, keyname):\n",
    "        if os.path.isfile(str(keyfile)):\n",
    "            keys_f = open(keyfile, 'r')\n",
    "            keys_json_string = keys_f.read()\n",
    "            keys_f.close()\n",
    "            keys = json.loads(keys_json_string)\n",
    "        else:\n",
    "            keys = keyfile\n",
    "        key_dict = keys[keyname]\n",
    "        self.authid = key_dict['key']\n",
    "        self.authpw = key_dict['secret']\n",
    "        self.server = key_dict['server']\n",
    "        if not self.server.endswith(\"/\"):\n",
    "            self.server += \"/\"\n",
    "\n",
    "            \n",
    "class ENC_Connection(object):\n",
    "    def __init__(self, key):\n",
    "        self.headers = {'content-type': 'application/json', 'accept': 'application/json'}\n",
    "        self.server = key.server\n",
    "        self.auth = (key.authid, key.authpw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define key if private data desired.\n",
    "key = ENC_Key(os.path.expanduser(\"~/keypairs.json\"), 'prod')\n",
    "auth = (key.authid, key.authpw)\n",
    "base_url = 'https://www.encodeproject.org'\n",
    "associated_search = urljoin(base_url, '/search/?type={}&{}={}&{}')\n",
    "json_all = 'limit=all&format=json'\n",
    "json_only = 'format=json'\n",
    "request_auth = aiohttp.BasicAuth(key.authid, key.authpw)\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_session():\n",
    "    connector = aiohttp.TCPConnector(keepalive_timeout=100, limit=100)\n",
    "    return aiohttp.ClientSession(connector=connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utils.\n",
    "\n",
    "def get_data(url):\n",
    "    r = requests.get(url, auth=auth)\n",
    "    try:\n",
    "        assert r.status_code == 200\n",
    "    except AssertionError as e:\n",
    "        raise Exception(url, r.text) from e\n",
    "    try:\n",
    "        return r.json()['@graph']\n",
    "    except KeyError:\n",
    "        return r.json()\n",
    "\n",
    "async def async_get_data(url, session, request_auth=request_auth):\n",
    "    r = await session.get(url, auth=request_auth)\n",
    "    try:\n",
    "        assert r.status == 200\n",
    "    except AssertionError as e:\n",
    "        raise Exception(url, await r.text()) from e\n",
    "    return await r.json()\n",
    "     \n",
    "def quick_grab_data(urls, session=session, loop=loop):\n",
    "    f = [async_get_data(url, session) for url in urls]\n",
    "    results = loop.run_until_complete(asyncio.gather(*f))\n",
    "    try:\n",
    "        return [subobject for item in results for subobject in item['@graph']]\n",
    "    except KeyError:\n",
    "        return results\n",
    "    \n",
    "def get_associated(item_type, related_field, related_ids):\n",
    "    urls = [associated_search.format(item_type,\n",
    "                                          related_field,\n",
    "                                          related_id,\n",
    "                                          json_all)\n",
    "            for related_id in related_ids]\n",
    "    return quick_grab_data(urls)\n",
    "\n",
    "def print_relation(relation):\n",
    "    for k, v in sorted(relation.items()):\n",
    "        print('tech_rep', k,\n",
    "              'in:', [(p[0], p[1]) for p in v['parents']],\n",
    "              'out:', [(c[0], c[1]) for c in v['children']], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "operator_map = {'equals': operator.eq,\n",
    "                'not_equals': operator.ne,\n",
    "                'contains': operator.contains}\n",
    "\n",
    "def process_stream(processors):\n",
    "    \"\"\"\n",
    "    Apply all processors to stream. Requires yield_files(files) to be passed\n",
    "    in as first item in list.\n",
    "    \"\"\"\n",
    "    stream = ()\n",
    "    for processor in processors:\n",
    "        stream = processor(stream)\n",
    "    return stream\n",
    "\n",
    "def processor(f):\n",
    "    \"\"\"\n",
    "    Return processor function applied to stream.\n",
    "    \"\"\"\n",
    "    @wraps(f)\n",
    "    def new_func(*args, **kwargs):\n",
    "        def processor(stream):\n",
    "            return f(stream, *args, **kwargs)\n",
    "        return processor\n",
    "    return new_func\n",
    "\n",
    "def generator(f):\n",
    "    \"\"\"\n",
    "    Return function that provides original data to stream.\n",
    "    \"\"\"\n",
    "    @wraps(f)\n",
    "    @processor\n",
    "    def new_func(stream, *args, **kwargs):\n",
    "        yield from f(*args, **kwargs)\n",
    "    return new_func\n",
    "\n",
    "@generator      \n",
    "def yield_files(files):\n",
    "    \"\"\"\n",
    "    Initiate processing stream with files.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        yield file\n",
    "\n",
    "@processor\n",
    "def filter_field_by_comparison(stream, field=None, value=None, comparison='equals'):\n",
    "    \"\"\"\n",
    "    Filter list of dictionaries based on field value, filter value, and comparison.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stream : generator\n",
    "        Original data plus applied processing steps passed in by @processor decorator.\n",
    "    field : string\n",
    "        Name of field in dictionary.\n",
    "    value : string or list (for contains)\n",
    "        Filter value to compare to field value.\n",
    "    comparison : {'equals' | 'not_equals' | 'contains'}\n",
    "        Operator used for comparing values. Default is equals.\n",
    "    \"\"\"\n",
    "    if operator_map.get(comparison) is None:\n",
    "        raise ValueError('Comparison must be one of: {}'.format(list(operator_map.keys())))\n",
    "    for file in stream:\n",
    "        # Make sure filter value exists.\n",
    "        if value is None:\n",
    "            raise ValueError('Must specify value')\n",
    "        # Continue if key not in specific file.\n",
    "        if file.get(field) is None:\n",
    "            continue\n",
    "        # Order of variables matter for contains.\n",
    "        left, right = value, file.get(field)\n",
    "        if comparison == 'contains' and isinstance(value, str):\n",
    "            left, right = file.get(field), value\n",
    "        # Yield only files that match filter.\n",
    "        if operator_map[comparison](left, right):\n",
    "            yield file\n",
    "\n",
    "def match(data, *args):\n",
    "    \"\"\"\n",
    "    Pass in data and filters.\n",
    "    \"\"\"\n",
    "    yield from process_stream([s for s in chain([yield_files(data)], [*args])])\n",
    "\n",
    "    \n",
    "def _find_relation(data, in_type, out_type, experiment):\n",
    "    parents =  list(match(data,\n",
    "                          filter_field_by_comparison(field='output_type',\n",
    "                                                     value=in_type['output_type']),\n",
    "                          filter_field_by_comparison(field='file_type',\n",
    "                                                     value=in_type['file_type']),\n",
    "                          filter_field_by_comparison(field='status',\n",
    "                                                     value=in_type['status'],\n",
    "                                                     comparison='contains')))\n",
    "    children = list(match(data,\n",
    "                          filter_field_by_comparison(field='output_type',\n",
    "                                                     value=out_type['output_type']),\n",
    "                          filter_field_by_comparison(field='file_type',\n",
    "                                                     value=out_type['file_type']),\n",
    "                          filter_field_by_comparison(field='status',\n",
    "                                                     value=out_type['status'],\n",
    "                                                     comparison='contains')))\n",
    "    return {'parents': [(p.get('accession', p.get('uuid')),\n",
    "                         p.get('file_type'),\n",
    "                         p.get('output_type'),\n",
    "                         p.get('status'),\n",
    "                         experiment) for p in parents],\n",
    "             'children': [(c.get('accession', c.get('uuid')),\n",
    "                         c.get('file_type'),\n",
    "                         c.get('output_type'),\n",
    "                         c.get('status'),\n",
    "                         experiment) for c in children]}\n",
    "\n",
    "\n",
    "def _extract_values_from_pattern(field, in_type, out_type):\n",
    "    \"\"\"\n",
    "    Returns set of values in both in_type and out_type for given field.\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    for value in chain([in_type], [out_type]):\n",
    "        # Flatten if value is a list.\n",
    "        if isinstance(value.get(field), list):\n",
    "            values.extend(value.get(field))\n",
    "        else:\n",
    "            values.append(value.get(field))\n",
    "    if None in values:\n",
    "        raise ValueError('Must specify {} in pattern.'.format(field))\n",
    "    return set(values)\n",
    "\n",
    "def basic_pattern(experiment, in_type, out_type, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns relationship of Files in Experiment given in_type and out_type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment : string\n",
    "        Accession of the Experiment of interest.\n",
    "    in_type : dict\n",
    "        (file_type, output_type, status, match_rep=True/False)\n",
    "    out_type : tuple\n",
    "        (file_type, output_type, status, match_rep=True/False)\n",
    "    **kwargs : string\n",
    "        Field name and filter value for additonal filters to apply to all associated files.\n",
    "    \"\"\"\n",
    "    additional_filters = []\n",
    "    calculated_relationships = {}\n",
    "    if in_type['match_rep'] != out_type['match_rep']:\n",
    "            raise ValueError('Match_rep mismatch between in and out pattern.')\n",
    "    # Pull pattern data.\n",
    "    filter_statuses = _extract_values_from_pattern('status', in_type, out_type)\n",
    "    filter_types = _extract_values_from_pattern('file_type', in_type, out_type)\n",
    "    filter_replicate = _extract_values_from_pattern('match_rep', in_type, out_type).pop()\n",
    "    # Optional filtering by fields passed to kwargs.\n",
    "    if kwargs:\n",
    "        for k,v in kwargs.items():\n",
    "            additional_filters.append(filter_field_by_comparison(field=k,\n",
    "                                                                 value=v,\n",
    "                                                                 comparison='equals'))\n",
    "    # Get all files associated with experiment.\n",
    "    associated_files = get_associated(item_type='File', related_field='dataset', related_ids=[experiment])\n",
    "    # Filter by status, file_formats, and additional_filters:\n",
    "    by_status_format_additional = list(match(associated_files,\n",
    "                                      filter_field_by_comparison(field='status',\n",
    "                                                         value=list(filter_statuses),\n",
    "                                                         comparison='contains'),\n",
    "                                      filter_field_by_comparison(field='file_type',\n",
    "                                                         value=list(filter_types),\n",
    "                                                         comparison='contains'), \n",
    "                                      *additional_filters))\n",
    "    if filter_replicate:\n",
    "        # Flatten lists of tech_reps.\n",
    "        tech_reps = set([tech_rep for f in by_status_format_additional\n",
    "                         for tech_rep in f['technical_replicates']])\n",
    "        # Match files by tech_rep.\n",
    "        for rep in tech_reps:\n",
    "            pairs = list(match(by_status_format_additional,\n",
    "                               filter_field_by_comparison(field='technical_replicates',\n",
    "                                                          value=str(rep),\n",
    "                                                          comparison='contains')))\n",
    "            calculated_relationships[rep] = _find_relation(pairs, in_type, out_type, experiment)\n",
    "    else:\n",
    "        calculated_relationships['None'] = _find_relation(by_status_format_additional, in_type, out_type, experiment)\n",
    "    return calculated_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RIP-seq patterns:\n",
    "in_type1 = dict(file_type='fastq', output_type='reads', status='released', match_rep=True)\n",
    "out_type1 = dict(file_type='bam', output_type='alignments', status='released', match_rep=True)\n",
    "\n",
    "in_type2 = dict(file_type='bam', output_type='alignments', status='released', match_rep=True)\n",
    "out_type2 = dict(file_type='bigWig', output_type='signal', status='released', match_rep=True)\n",
    "\n",
    "in_type3 = dict(file_type='bam', output_type='alignments', status='released', match_rep=False)\n",
    "out_type3 = dict(file_type='bed broadPeak', output_type='peaks', status='released', match_rep=False)\n",
    "\n",
    "in_type4 = dict(file_type='bed broadPeak', output_type='peaks', status='released', match_rep=False)\n",
    "out_type4 = dict(file_type='bigBed broadPeak', output_type='peaks', status='released', match_rep=False)\n",
    "\n",
    "# Build list of results.\n",
    "relationships = [basic_pattern(experiment_id, in_type1, out_type1),\n",
    "                 basic_pattern(experiment_id, in_type2, out_type2),\n",
    "                 basic_pattern(experiment_id, in_type3, out_type3),\n",
    "                 basic_pattern(experiment_id, in_type4, out_type4)]\n",
    "\n",
    "# Gingeras RNA microarray patterns:\n",
    "url = 'https://www.encodeproject.org/search/?type=Experiment&assay_title=RNA+microarray&audit.INTERNAL_ACTION.category=missing+derived_from&award.rfa=ENCODE2&lab.title=Thomas+Gingeras%2C+CSHL&format=json&limit=all'\n",
    "in_type1 = dict(file_type='bed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type1 = dict(file_type='bigBed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "\n",
    "in_type2 = dict(file_type='bed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type2 = dict(file_type='bigBed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "\n",
    "in_type3 = dict(file_type='bed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type3 = dict(file_type='bed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "\n",
    "url = 'https://www.encodeproject.org/search/?type=Experiment&assay_title=RNA+microarray&lab.title=Gregory+Crawford%2C+Duke&audit.INTERNAL_ACTION.category=missing+derived_from&format=json&limit=all'\n",
    "# Crawford RNA microarray pattern:\n",
    "in_type1 = dict(file_type='bed broadPeak', output_type='exon quantifications', status=['released', 'deleted', 'revoked'], match_rep=True)\n",
    "out_type1 = dict(file_type='bigBed broadPeak', output_type='exon quantifications', status=['released', 'deleted', 'revoked'], match_rep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.encodeproject.org/search/?type=Experiment&assay_title=RNA+microarray&lab.title=Gregory+Crawford%2C+Duke&audit.INTERNAL_ACTION.category=missing+derived_from&format=json&limit=all'\n",
    "exp = [f['@id'] for f in quick_grab_data([url])]\n",
    "len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for e in exp:\n",
    "    experiment_id = e\n",
    "    relationships = [basic_pattern(experiment_id, in_type1, out_type1)]\n",
    "    results.append(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfpd = []\n",
    "for x in results:\n",
    "    for y in x:\n",
    "        for k, v in y.items():\n",
    "            d = {'accession': ' '.join([t[0] for t in v['children']]),\n",
    "                 'derived_from:list': ','.join(['/files/{}/'.format(t[0]) for t in v['parents']])}\n",
    "            dfpd.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>derived_from:list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENCFF000KMY</td>\n",
       "      <td>/files/ENCFF001TFE/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCFF000KNE</td>\n",
       "      <td>/files/ENCFF001TFG/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCFF000KNA</td>\n",
       "      <td>/files/ENCFF001TFF/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENCFF000KMW</td>\n",
       "      <td>/files/ENCFF001TFD/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENCFF000KMO</td>\n",
       "      <td>/files/ENCFF001TEZ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENCFF000KMQ</td>\n",
       "      <td>/files/ENCFF001TFA/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENCFF000KJQ</td>\n",
       "      <td>/files/ENCFF001TDR/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENCFF000KJS</td>\n",
       "      <td>/files/ENCFF001TDS/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENCFF000KTQ</td>\n",
       "      <td>/files/ENCFF001THS/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENCFF000KKJ</td>\n",
       "      <td>/files/ENCFF001TEA/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENCFF000KKI</td>\n",
       "      <td>/files/ENCFF001TDZ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENCFF000KOT</td>\n",
       "      <td>/files/ENCFF001TFX/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENCFF000KOR</td>\n",
       "      <td>/files/ENCFF001TFW/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENCFF000KSU</td>\n",
       "      <td>/files/ENCFF001THJ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENCFF000KSS</td>\n",
       "      <td>/files/ENCFF001THI/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENCFF000KRQ</td>\n",
       "      <td>/files/ENCFF001TGX/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ENCFF000KRS</td>\n",
       "      <td>/files/ENCFF001TGY/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ENCFF000KSC</td>\n",
       "      <td>/files/ENCFF001THC/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENCFF000KSE</td>\n",
       "      <td>/files/ENCFF001THD/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENCFF000KSG</td>\n",
       "      <td>/files/ENCFF001THE/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENCFF000KSI</td>\n",
       "      <td>/files/ENCFF001THF/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ENCFF000KTP</td>\n",
       "      <td>/files/ENCFF001THQ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ENCFF000KRI</td>\n",
       "      <td>/files/ENCFF001TGV/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ENCFF000KRG</td>\n",
       "      <td>/files/ENCFF001TGU/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ENCFF000KQX</td>\n",
       "      <td>/files/ENCFF001TGR/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ENCFF000KQV</td>\n",
       "      <td>/files/ENCFF001TGQ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ENCFF000KNT</td>\n",
       "      <td>/files/ENCFF001TFK/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ENCFF000KNV</td>\n",
       "      <td>/files/ENCFF001TFL/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ENCFF000KLW</td>\n",
       "      <td>/files/ENCFF001TEQ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ENCFF000KLY</td>\n",
       "      <td>/files/ENCFF001TER/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ENCFF000KLS</td>\n",
       "      <td>/files/ENCFF001TEO/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ENCFF000KLU</td>\n",
       "      <td>/files/ENCFF001TEP/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ENCFF000KKE</td>\n",
       "      <td>/files/ENCFF001TDX/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ENCFF000KKG</td>\n",
       "      <td>/files/ENCFF001TDY/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ENCFF000KMM</td>\n",
       "      <td>/files/ENCFF001TEY/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ENCFF000KMK</td>\n",
       "      <td>/files/ENCFF001TEX/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ENCFF000KPG</td>\n",
       "      <td>/files/ENCFF001TGC/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ENCFF000KPE</td>\n",
       "      <td>/files/ENCFF001TGB/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ENCFF000KPI</td>\n",
       "      <td>/files/ENCFF001TGD/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ENCFF000KOH</td>\n",
       "      <td>/files/ENCFF001TFR/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ENCFF000KOJ</td>\n",
       "      <td>/files/ENCFF001TFS/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ENCFF000KOL</td>\n",
       "      <td>/files/ENCFF001TFT/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ENCFF000KKX</td>\n",
       "      <td>/files/ENCFF001TEH/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ENCFF000KKW</td>\n",
       "      <td>/files/ENCFF001TEG/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCFF000KKY</td>\n",
       "      <td>/files/ENCFF001TEI/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ENCFF000KRU</td>\n",
       "      <td>/files/ENCFF001TGZ/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ENCFF000KRW</td>\n",
       "      <td>/files/ENCFF001THA/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ENCFF000KRY</td>\n",
       "      <td>/files/ENCFF001THB/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ENCFF000KRO</td>\n",
       "      <td>/files/ENCFF001TGW/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ENCFF000KJW</td>\n",
       "      <td>/files/ENCFF001TDT/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ENCFF000KJY</td>\n",
       "      <td>/files/ENCFF001TDU/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ENCFF000KMS</td>\n",
       "      <td>/files/ENCFF001TFB/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ENCFF000KMU</td>\n",
       "      <td>/files/ENCFF001TFC/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ENCFF000KPP</td>\n",
       "      <td>/files/ENCFF001TGF/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ENCFF000KPN</td>\n",
       "      <td>/files/ENCFF001TGE/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ENCFF000KMA</td>\n",
       "      <td>/files/ENCFF001TES/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ENCFF000KMC</td>\n",
       "      <td>/files/ENCFF001TET/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ENCFF000KTA</td>\n",
       "      <td>/files/ENCFF001THL/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ENCFF000KSZ</td>\n",
       "      <td>/files/ENCFF001THK/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ENCFF000KTB</td>\n",
       "      <td>/files/ENCFF001THM/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accession    derived_from:list\n",
       "0    ENCFF000KMY  /files/ENCFF001TFE/\n",
       "1    ENCFF000KNE  /files/ENCFF001TFG/\n",
       "2    ENCFF000KNA  /files/ENCFF001TFF/\n",
       "3    ENCFF000KMW  /files/ENCFF001TFD/\n",
       "4    ENCFF000KMO  /files/ENCFF001TEZ/\n",
       "5    ENCFF000KMQ  /files/ENCFF001TFA/\n",
       "6    ENCFF000KJQ  /files/ENCFF001TDR/\n",
       "7    ENCFF000KJS  /files/ENCFF001TDS/\n",
       "8    ENCFF000KTQ  /files/ENCFF001THS/\n",
       "9    ENCFF000KKJ  /files/ENCFF001TEA/\n",
       "10   ENCFF000KKI  /files/ENCFF001TDZ/\n",
       "11   ENCFF000KOT  /files/ENCFF001TFX/\n",
       "12   ENCFF000KOR  /files/ENCFF001TFW/\n",
       "13   ENCFF000KSU  /files/ENCFF001THJ/\n",
       "14   ENCFF000KSS  /files/ENCFF001THI/\n",
       "15   ENCFF000KRQ  /files/ENCFF001TGX/\n",
       "16   ENCFF000KRS  /files/ENCFF001TGY/\n",
       "17   ENCFF000KSC  /files/ENCFF001THC/\n",
       "18   ENCFF000KSE  /files/ENCFF001THD/\n",
       "19   ENCFF000KSG  /files/ENCFF001THE/\n",
       "20   ENCFF000KSI  /files/ENCFF001THF/\n",
       "21   ENCFF000KTP  /files/ENCFF001THQ/\n",
       "22   ENCFF000KRI  /files/ENCFF001TGV/\n",
       "23   ENCFF000KRG  /files/ENCFF001TGU/\n",
       "24   ENCFF000KQX  /files/ENCFF001TGR/\n",
       "25   ENCFF000KQV  /files/ENCFF001TGQ/\n",
       "26   ENCFF000KNT  /files/ENCFF001TFK/\n",
       "27   ENCFF000KNV  /files/ENCFF001TFL/\n",
       "28   ENCFF000KLW  /files/ENCFF001TEQ/\n",
       "29   ENCFF000KLY  /files/ENCFF001TER/\n",
       "..           ...                  ...\n",
       "75   ENCFF000KLS  /files/ENCFF001TEO/\n",
       "76   ENCFF000KLU  /files/ENCFF001TEP/\n",
       "77   ENCFF000KKE  /files/ENCFF001TDX/\n",
       "78   ENCFF000KKG  /files/ENCFF001TDY/\n",
       "79   ENCFF000KMM  /files/ENCFF001TEY/\n",
       "80   ENCFF000KMK  /files/ENCFF001TEX/\n",
       "81   ENCFF000KPG  /files/ENCFF001TGC/\n",
       "82   ENCFF000KPE  /files/ENCFF001TGB/\n",
       "83   ENCFF000KPI  /files/ENCFF001TGD/\n",
       "84   ENCFF000KOH  /files/ENCFF001TFR/\n",
       "85   ENCFF000KOJ  /files/ENCFF001TFS/\n",
       "86   ENCFF000KOL  /files/ENCFF001TFT/\n",
       "87   ENCFF000KKX  /files/ENCFF001TEH/\n",
       "88   ENCFF000KKW  /files/ENCFF001TEG/\n",
       "89   ENCFF000KKY  /files/ENCFF001TEI/\n",
       "90   ENCFF000KRU  /files/ENCFF001TGZ/\n",
       "91   ENCFF000KRW  /files/ENCFF001THA/\n",
       "92   ENCFF000KRY  /files/ENCFF001THB/\n",
       "93   ENCFF000KRO  /files/ENCFF001TGW/\n",
       "94   ENCFF000KJW  /files/ENCFF001TDT/\n",
       "95   ENCFF000KJY  /files/ENCFF001TDU/\n",
       "96   ENCFF000KMS  /files/ENCFF001TFB/\n",
       "97   ENCFF000KMU  /files/ENCFF001TFC/\n",
       "98   ENCFF000KPP  /files/ENCFF001TGF/\n",
       "99   ENCFF000KPN  /files/ENCFF001TGE/\n",
       "100  ENCFF000KMA  /files/ENCFF001TES/\n",
       "101  ENCFF000KMC  /files/ENCFF001TET/\n",
       "102  ENCFF000KTA  /files/ENCFF001THL/\n",
       "103  ENCFF000KSZ  /files/ENCFF001THK/\n",
       "104  ENCFF000KTB  /files/ENCFF001THM/\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfpd).replace('', np.nan).dropna().reset_index(drop=True)\\\n",
    "#.to_csv('../../calculated_derived_from_crawford_rna_microarray_patch_10_20_2017.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.encodeproject.org/search/?type=Experiment&assay_title=RNA+microarray&audit.INTERNAL_ACTION.category=missing+derived_from&award.rfa=ENCODE2&lab.title=Thomas+Gingeras%2C+CSHL&format=json&limit=all'\n",
    "exp = [f['accession'] for f in quick_grab_data([url])]\n",
    "\n",
    "in_type1 = dict(file_type='bed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type1 = dict(file_type='bigBed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "\n",
    "in_type2 = dict(file_type='bed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type2 = dict(file_type='bigBed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "\n",
    "in_type3 = dict(file_type='bed broadPeak', output_type='transcribed fragments', status=['revoked', 'released'], match_rep=False)\n",
    "out_type3 = dict(file_type='bed broadPeak', output_type='filtered transcribed fragments', status=['revoked', 'released'], match_rep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For: /experiments/ENCSR000AWA/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNI', 'bed broadPeak')] out: [('ENCFF000ABS', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMI', 'bed broadPeak')] out: [('ENCFF000AAV', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNI', 'bed broadPeak')] out: [('ENCFF001SMI', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWM/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNW', 'bed broadPeak')] out: [('ENCFF000ACI', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMW', 'bed broadPeak')] out: [('ENCFF000ABI', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNW', 'bed broadPeak')] out: [('ENCFF001SMW', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWJ/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNR', 'bed broadPeak')] out: [('ENCFF000ACD', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMR', 'bed broadPeak')] out: [('ENCFF000ABD', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNR', 'bed broadPeak')] out: [('ENCFF001SMR', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWN/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNV', 'bed broadPeak')] out: [('ENCFF000ACH', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMV', 'bed broadPeak')] out: [('ENCFF000ABH', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNV', 'bed broadPeak')] out: [('ENCFF001SMV', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWI/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOI', 'bed broadPeak')] out: [('ENCFF000ACR', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNF', 'bed broadPeak')] out: [('ENCFF000ABU', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOI', 'bed broadPeak')] out: [('ENCFF001SNF', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWD/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNT', 'bed broadPeak')] out: [('ENCFF000ACF', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMT', 'bed broadPeak')] out: [('ENCFF000ABF', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNT', 'bed broadPeak')] out: [('ENCFF001SMT', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWV/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOD', 'bed broadPeak')] out: [('ENCFF000ACP', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SND', 'bed broadPeak')] out: [('ENCFF000ABP', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOD', 'bed broadPeak')] out: [('ENCFF001SND', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWR/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNN', 'bed broadPeak')] out: [('ENCFF000ABZ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMN', 'bed broadPeak')] out: [('ENCFF000AAZ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNN', 'bed broadPeak')] out: [('ENCFF001SMN', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWY/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNJ', 'bed broadPeak')] out: [('ENCFF000ABV', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMJ', 'bed broadPeak')] out: [('ENCFF000AAU', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNJ', 'bed broadPeak')] out: [('ENCFF001SMJ', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWB/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNK', 'bed broadPeak')] out: [('ENCFF000ABW', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMK', 'bed broadPeak')] out: [('ENCFF000AAW', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNK', 'bed broadPeak')] out: [('ENCFF001SMK', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWU/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOC', 'bed broadPeak')] out: [('ENCFF000ACO', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNC', 'bed broadPeak')] out: [('ENCFF000ABO', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOC', 'bed broadPeak')] out: [('ENCFF001SNC', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWQ/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNM', 'bed broadPeak')] out: [('ENCFF000ABY', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMM', 'bed broadPeak')] out: [('ENCFF000AAY', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNM', 'bed broadPeak')] out: [('ENCFF001SMM', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWK/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNH', 'bed broadPeak')] out: [('ENCFF000ABQ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMH', 'bed broadPeak')] out: [('ENCFF000AAT', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNH', 'bed broadPeak')] out: [('ENCFF001SMH', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWX/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNQ', 'bed broadPeak')] out: [('ENCFF000ACC', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMQ', 'bed broadPeak')] out: [('ENCFF000ABC', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNQ', 'bed broadPeak')] out: [('ENCFF001SMQ', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWW/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNP', 'bed broadPeak')] out: [('ENCFF000ACB', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMP', 'bed broadPeak')] out: [('ENCFF000ABB', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNP', 'bed broadPeak')] out: [('ENCFF001SMP', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWL/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNS', 'bed broadPeak')] out: [('ENCFF000ACE', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMS', 'bed broadPeak')] out: [('ENCFF000ABE', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNS', 'bed broadPeak')] out: [('ENCFF001SMS', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWZ/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNO', 'bed broadPeak')] out: [('ENCFF000ACA', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMO', 'bed broadPeak')] out: [('ENCFF000ABA', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNO', 'bed broadPeak')] out: [('ENCFF001SMO', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWE/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNU', 'bed broadPeak')] out: [('ENCFF000ACG', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMU', 'bed broadPeak')] out: [('ENCFF000ABG', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNU', 'bed broadPeak')] out: [('ENCFF001SMU', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWH/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOE', 'bed broadPeak')] out: [('ENCFF000ACQ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNE', 'bed broadPeak')] out: [('ENCFF000ABT', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOE', 'bed broadPeak')] out: [('ENCFF001SNE', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWS/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOA', 'bed broadPeak')] out: [('ENCFF000ACM', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNA', 'bed broadPeak')] out: [('ENCFF000ABM', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOA', 'bed broadPeak')] out: [('ENCFF001SNA', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWO/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNG', 'bed broadPeak')] out: [('ENCFF000ABR', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMG', 'bed broadPeak')] out: [('ENCFF000AAS', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNG', 'bed broadPeak')] out: [('ENCFF001SMG', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWP/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNL', 'bed broadPeak')] out: [('ENCFF000ABX', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SML', 'bed broadPeak')] out: [('ENCFF000AAX', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNL', 'bed broadPeak')] out: [('ENCFF001SML', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWC/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNZ', 'bed broadPeak')] out: [('ENCFF000ACL', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMZ', 'bed broadPeak')] out: [('ENCFF000ABL', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNZ', 'bed broadPeak')] out: [('ENCFF001SMZ', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWF/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNX', 'bed broadPeak')] out: [('ENCFF000ACJ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMX', 'bed broadPeak')] out: [('ENCFF000ABJ', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNX', 'bed broadPeak')] out: [('ENCFF001SMX', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWG/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNY', 'bed broadPeak')] out: [('ENCFF000ACK', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SMY', 'bed broadPeak')] out: [('ENCFF000ABK', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNY', 'bed broadPeak')] out: [('ENCFF001SMY', 'bed broadPeak')]\n",
      "\n",
      "\n",
      "For: /experiments/ENCSR000AWT/\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOB', 'bed broadPeak')] out: [('ENCFF000ACN', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SNB', 'bed broadPeak')] out: [('ENCFF000ABN', 'bigBed broadPeak')]\n",
      "\n",
      "tech_rep None in: [('ENCFF001SOB', 'bed broadPeak')] out: [('ENCFF001SNB', 'bed broadPeak')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in exp:\n",
    "    print()\n",
    "    experiment_id = '/experiments/{}/'.format(e)\n",
    "    relationships = [basic_pattern(experiment_id, in_type1, out_type1),\n",
    "                     basic_pattern(experiment_id, in_type2, out_type2),\n",
    "                     basic_pattern(experiment_id, in_type3, out_type3)]\n",
    "    print('For:', experiment_id, end='\\n\\n')\n",
    "    for i, relation in enumerate(relationships):\n",
    "        print_relation(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
